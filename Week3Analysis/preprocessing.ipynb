{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import webcolors\n",
    "from webcolors import hex_to_name\n",
    "from PIL import ImageColor\n",
    "import numpy as np\n",
    "import pyarrow.csv as pv\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute CSS3 color information for vectorized closest_color function\n",
    "CSS3_COLOR_RGB = {name: webcolors.name_to_rgb(name) for name in webcolors.names(\"css3\")}\n",
    "CSS3_COLOR_NAMES = np.array(list(CSS3_COLOR_RGB.keys()))\n",
    "CSS3_COLOR_VALUES = np.array(list(CSS3_COLOR_RGB.values()))  # Shape: (n_colors, 3)\n",
    "\n",
    "# Vectorized function to find the closest CSS3 colors for a list of RGB colors\n",
    "def closest_color_vectorized(requested_colors):\n",
    "    \"\"\"\n",
    "    Find the closest CSS3 colors for a list of RGB colors using vectorized computation.\n",
    "    \"\"\"\n",
    "    requested_colors_np = np.array(requested_colors)  # Convert to NumPy array (n_samples, 3)\n",
    "    distances = np.sum((CSS3_COLOR_VALUES[None, :, :] - requested_colors_np[:, None, :]) ** 2, axis=2)\n",
    "    closest_indices = np.argmin(distances, axis=1)  # Find the index of the closest color for each input\n",
    "    return CSS3_COLOR_NAMES[closest_indices]  # Return the closest color names as a vector\n",
    "\n",
    "# Optimized function to get the English name for a pixel color (vectorized)\n",
    "def get_color_name_vectorized(hex_values):\n",
    "    \"\"\"\n",
    "    Convert a list of hex colors to their English names or the closest color names.\n",
    "    \"\"\"\n",
    "    # Convert hex colors to RGB\n",
    "    rgb_colors = [ImageColor.getcolor(hex_value, \"RGB\") for hex_value in hex_values]\n",
    "\n",
    "    # Use the vectorized closest_color function to get the names\n",
    "    return closest_color_vectorized(rgb_colors)\n",
    "\n",
    "# User ID remapping function with global dictionary for consistent remapping\n",
    "user_id_dict = {}\n",
    "user_id_counter = 0\n",
    "\n",
    "def map_user_id_vectorized(user_ids):\n",
    "    \"\"\"\n",
    "    Map a list of user IDs to incremental integer IDs.\n",
    "    \"\"\"\n",
    "    global user_id_counter\n",
    "    mapped_ids = []\n",
    "    for user_id in user_ids:\n",
    "        if user_id not in user_id_dict:\n",
    "            user_id_counter += 1\n",
    "            user_id_dict[user_id] = user_id_counter\n",
    "        mapped_ids.append(user_id_dict[user_id])\n",
    "    return np.array(mapped_ids)  # Return as a NumPy array for compatibility with vectorized processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.46%\n",
      "Progress: 0.92%\n",
      "Progress: 1.38%\n",
      "Progress: 1.84%\n",
      "Progress: 2.29%\n",
      "Progress: 2.75%\n",
      "Progress: 3.21%\n",
      "Progress: 3.67%\n",
      "Progress: 4.13%\n",
      "Progress: 4.59%\n",
      "Progress: 5.05%\n",
      "Progress: 5.51%\n",
      "Progress: 5.97%\n",
      "Progress: 6.43%\n",
      "Progress: 6.89%\n",
      "Progress: 7.36%\n",
      "Progress: 7.82%\n",
      "Progress: 8.28%\n",
      "Progress: 8.74%\n",
      "Progress: 9.21%\n",
      "Progress: 9.66%\n",
      "Progress: 10.12%\n",
      "Progress: 10.59%\n",
      "Progress: 11.05%\n",
      "Progress: 11.51%\n",
      "Progress: 11.98%\n",
      "Progress: 12.44%\n",
      "Progress: 12.90%\n",
      "Progress: 13.37%\n",
      "Progress: 13.83%\n",
      "Progress: 14.29%\n",
      "Progress: 14.76%\n",
      "Progress: 15.22%\n",
      "Progress: 15.68%\n",
      "Progress: 16.14%\n",
      "Progress: 16.61%\n",
      "Progress: 17.07%\n",
      "Progress: 17.53%\n",
      "Progress: 18.00%\n",
      "Progress: 18.46%\n",
      "Progress: 18.92%\n",
      "Progress: 19.39%\n",
      "Progress: 19.85%\n",
      "Progress: 20.31%\n",
      "Progress: 20.78%\n",
      "Progress: 21.24%\n",
      "Progress: 21.70%\n",
      "Progress: 22.17%\n",
      "Progress: 22.63%\n",
      "Progress: 23.09%\n",
      "Progress: 23.55%\n",
      "Progress: 24.01%\n",
      "Progress: 24.48%\n",
      "Progress: 24.94%\n",
      "Progress: 25.40%\n",
      "Progress: 25.86%\n",
      "Progress: 26.32%\n",
      "Progress: 26.78%\n",
      "Progress: 27.25%\n",
      "Progress: 27.71%\n",
      "Progress: 28.17%\n",
      "Progress: 28.63%\n",
      "Progress: 29.09%\n",
      "Progress: 29.55%\n",
      "Progress: 30.01%\n",
      "Progress: 30.48%\n",
      "Progress: 30.94%\n",
      "Progress: 31.40%\n",
      "Progress: 31.86%\n",
      "Progress: 32.32%\n",
      "Progress: 32.78%\n",
      "Progress: 33.25%\n",
      "Progress: 33.71%\n",
      "Progress: 34.17%\n",
      "Progress: 34.63%\n",
      "Progress: 35.09%\n",
      "Progress: 35.55%\n",
      "Progress: 36.01%\n",
      "Progress: 36.47%\n",
      "Progress: 36.93%\n",
      "Progress: 37.39%\n",
      "Progress: 37.85%\n",
      "Progress: 38.31%\n",
      "Progress: 38.77%\n",
      "Progress: 39.24%\n",
      "Progress: 39.70%\n",
      "Progress: 40.16%\n",
      "Progress: 40.62%\n",
      "Progress: 41.08%\n",
      "Progress: 41.54%\n",
      "Progress: 42.00%\n",
      "Progress: 42.47%\n",
      "Progress: 42.93%\n",
      "Progress: 43.39%\n",
      "Progress: 43.85%\n",
      "Progress: 44.31%\n",
      "Progress: 44.77%\n",
      "Progress: 45.23%\n",
      "Progress: 45.70%\n",
      "Progress: 46.16%\n",
      "Progress: 46.62%\n",
      "Progress: 47.08%\n",
      "Progress: 47.54%\n",
      "Progress: 48.01%\n",
      "Progress: 48.47%\n",
      "Progress: 48.93%\n",
      "Progress: 49.39%\n",
      "Progress: 49.85%\n",
      "Progress: 50.31%\n",
      "Progress: 50.77%\n",
      "Progress: 51.23%\n",
      "Progress: 51.69%\n",
      "Progress: 52.15%\n",
      "Progress: 52.61%\n",
      "Progress: 53.07%\n",
      "Progress: 53.53%\n",
      "Progress: 53.99%\n",
      "Progress: 54.46%\n",
      "Progress: 54.92%\n",
      "Progress: 55.38%\n",
      "Progress: 55.84%\n",
      "Progress: 56.30%\n",
      "Progress: 56.76%\n",
      "Progress: 57.22%\n",
      "Progress: 57.68%\n",
      "Progress: 58.14%\n",
      "Progress: 58.60%\n",
      "Progress: 59.05%\n",
      "Progress: 59.51%\n",
      "Progress: 59.97%\n",
      "Progress: 60.43%\n",
      "Progress: 60.89%\n",
      "Progress: 61.35%\n",
      "Progress: 61.81%\n",
      "Progress: 62.27%\n",
      "Progress: 62.73%\n",
      "Progress: 63.19%\n",
      "Progress: 63.65%\n",
      "Progress: 64.11%\n",
      "Progress: 64.57%\n",
      "Progress: 65.02%\n",
      "Progress: 65.48%\n",
      "Progress: 65.94%\n",
      "Progress: 66.40%\n",
      "Progress: 66.86%\n",
      "Progress: 67.32%\n",
      "Progress: 67.78%\n",
      "Progress: 68.24%\n",
      "Progress: 68.70%\n",
      "Progress: 69.16%\n",
      "Progress: 69.62%\n",
      "Progress: 70.08%\n",
      "Progress: 70.54%\n",
      "Progress: 71.00%\n",
      "Progress: 71.46%\n",
      "Progress: 71.91%\n",
      "Progress: 72.37%\n",
      "Progress: 72.83%\n",
      "Progress: 73.29%\n",
      "Progress: 73.75%\n",
      "Progress: 74.21%\n",
      "Progress: 74.67%\n",
      "Progress: 75.13%\n",
      "Progress: 75.59%\n",
      "Progress: 76.05%\n",
      "Progress: 76.51%\n",
      "Progress: 76.97%\n",
      "Progress: 77.43%\n",
      "Progress: 77.89%\n",
      "Progress: 78.35%\n",
      "Progress: 78.81%\n",
      "Progress: 79.27%\n",
      "Progress: 79.73%\n",
      "Progress: 80.18%\n",
      "Progress: 80.64%\n",
      "Progress: 81.10%\n",
      "Progress: 81.56%\n",
      "Progress: 82.02%\n",
      "Progress: 82.48%\n",
      "Progress: 82.94%\n",
      "Progress: 83.40%\n",
      "Progress: 83.86%\n",
      "Progress: 84.32%\n",
      "Progress: 84.78%\n",
      "Progress: 85.24%\n",
      "Progress: 85.70%\n",
      "Progress: 86.15%\n",
      "Progress: 86.61%\n",
      "Progress: 87.07%\n",
      "Progress: 87.53%\n",
      "Progress: 87.99%\n",
      "Progress: 88.45%\n",
      "Progress: 88.91%\n",
      "Progress: 89.37%\n",
      "Progress: 89.83%\n",
      "Progress: 90.29%\n",
      "Progress: 90.75%\n",
      "Progress: 91.21%\n",
      "Progress: 91.67%\n",
      "Progress: 92.13%\n",
      "Progress: 92.59%\n",
      "Progress: 93.05%\n",
      "Progress: 93.50%\n",
      "Progress: 93.96%\n",
      "Progress: 94.42%\n",
      "Progress: 94.88%\n",
      "Progress: 95.34%\n",
      "Progress: 95.80%\n",
      "Progress: 96.26%\n",
      "Progress: 96.72%\n",
      "Progress: 97.18%\n",
      "Progress: 97.64%\n",
      "Progress: 98.10%\n",
      "Progress: 98.55%\n",
      "Progress: 99.01%\n",
      "Progress: 99.47%\n",
      "Progress: 99.93%\n",
      "Progress: 100.00%\n",
      "Successfully converted ./../2022_place_canvas_history.csv to ./../2022_rplace.parquet\n"
     ]
    }
   ],
   "source": [
    "# Input and output file paths\n",
    "csv_file = \"./../2022_place_canvas_history.csv\"\n",
    "parquet_file = \"./../2022_rplace.parquet\"\n",
    "\n",
    "# Configuration constants\n",
    "DATESTRING_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n",
    "BATCH_SIZE = 100_000_000  # Number of rows per batch\n",
    "\n",
    "# Calculate total rows in the CSV file\n",
    "total_rows = sum(1 for _ in open(csv_file)) - 1  # Subtract 1 for the header row\n",
    "processed_rows = 0  # Initialize a counter for processed rows\n",
    "\n",
    "# Open CSV file in batches\n",
    "csv_reader = pv.open_csv(csv_file, read_options=pv.ReadOptions(block_size=BATCH_SIZE))\n",
    "\n",
    "# Initialize Parquet writer\n",
    "parquet_writer = None\n",
    "\n",
    "try:\n",
    "    for record_batch in csv_reader:\n",
    "        batch_rows = record_batch.num_rows\n",
    "        processed_rows += batch_rows\n",
    "\n",
    "        # Convert Arrow record batch to Polars DataFrame\n",
    "        df = pl.from_arrow(record_batch)\n",
    "\n",
    "        # Process timestamp column\n",
    "        df = df.with_columns(\n",
    "            pl.col(\"timestamp\")\n",
    "            .str.replace(r\" UTC$\", \"\")\n",
    "            .str.strptime(\n",
    "                pl.Datetime, format=\"%Y-%m-%d %H:%M:%S%.f\", strict=False\n",
    "            )\n",
    "            .alias(\"timestamp\")\n",
    "        )\n",
    "\n",
    "       # Convert pixel_color column to English names (vectorized)\n",
    "        pixel_colors = df[\"pixel_color\"].to_list()\n",
    "        color_names = get_color_name_vectorized(pixel_colors)\n",
    "        df = df.with_columns(pl.Series(name=\"pixel_color_english\", values=color_names))\n",
    "\n",
    "        # Map user_id column to incremental IDs (vectorized)\n",
    "        user_ids = df[\"user_id\"].to_list()\n",
    "        mapped_ids = map_user_id_vectorized(user_ids)\n",
    "        df = df.with_columns(pl.Series(name=\"user_id_int\", values=mapped_ids))\n",
    "        \n",
    "        \n",
    "        # Drop the original pixel_color and user_id columns\n",
    "        df = df.drop([\"pixel_color\", \"user_id\"])\n",
    "\n",
    "        # Filter and process coordinate column\n",
    "        df = (\n",
    "            df.filter(\n",
    "                pl.col(\"coordinate\").str.count_matches(\",\") == 1\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.col(\"coordinate\")\n",
    "                .str.split_exact(\",\", 1)\n",
    "                .struct.field(\"field_0\")\n",
    "                .cast(pl.Int64)\n",
    "                .alias(\"x\"),\n",
    "                pl.col(\"coordinate\")\n",
    "                .str.split_exact(\",\", 1)\n",
    "                .struct.field(\"field_1\")\n",
    "                .cast(pl.Int64)\n",
    "                .alias(\"y\"),\n",
    "            )\n",
    "            .drop(\"coordinate\")\n",
    "        )\n",
    "\n",
    "        # Convert Polars DataFrame to Arrow Table\n",
    "        table = df.to_arrow()\n",
    "\n",
    "        # Initialize ParquetWriter with schema if not already set\n",
    "        if parquet_writer is None:\n",
    "            parquet_writer = pq.ParquetWriter(\n",
    "                parquet_file, schema=table.schema, compression=\"zstd\"\n",
    "            )\n",
    "\n",
    "        # Write the table to the Parquet file\n",
    "        parquet_writer.write_table(table)\n",
    "\n",
    "        # Print progress as percentage\n",
    "        progress = (processed_rows / total_rows) * 100\n",
    "        print(f\"Progress: {progress:.2f}%\")\n",
    "\n",
    "finally:\n",
    "    # Close the Parquet writer\n",
    "    if parquet_writer:\n",
    "        parquet_writer.close()\n",
    "\n",
    "print(f\"Successfully converted {csv_file} to {parquet_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (160_353_085, 5)\n",
      "┌─────────────────────────┬─────────────────────┬─────────────┬──────┬──────┐\n",
      "│ timestamp               ┆ pixel_color_english ┆ user_id_int ┆ x    ┆ y    │\n",
      "│ ---                     ┆ ---                 ┆ ---         ┆ ---  ┆ ---  │\n",
      "│ datetime[μs]            ┆ str                 ┆ i64         ┆ i64  ┆ i64  │\n",
      "╞═════════════════════════╪═════════════════════╪═════════════╪══════╪══════╡\n",
      "│ 2022-04-04 00:53:51.577 ┆ darkturquoise       ┆ 1           ┆ 826  ┆ 1048 │\n",
      "│ 2022-04-04 00:53:53.758 ┆ lightskyblue        ┆ 2           ┆ 583  ┆ 1031 │\n",
      "│ 2022-04-04 00:53:54.685 ┆ mediumslateblue     ┆ 3           ┆ 1873 ┆ 558  │\n",
      "│ 2022-04-04 00:54:57.541 ┆ darkcyan            ┆ 4           ┆ 1627 ┆ 255  │\n",
      "│ 2022-04-04 00:55:16.307 ┆ lightskyblue        ┆ 5           ┆ 49   ┆ 1478 │\n",
      "│ …                       ┆ …                   ┆ …           ┆ …    ┆ …    │\n",
      "│ 2022-04-05 00:14:00.066 ┆ white               ┆ 2119678     ┆ 408  ┆ 493  │\n",
      "│ 2022-04-05 00:14:00.145 ┆ white               ┆ 862796      ┆ 1232 ┆ 312  │\n",
      "│ 2022-04-05 00:14:00.172 ┆ white               ┆ 2778755     ┆ 770  ┆ 866  │\n",
      "│ 2022-04-05 00:14:00.195 ┆ white               ┆ 1591568     ┆ 1046 ┆ 1721 │\n",
      "│ 2022-04-05 00:14:00.207 ┆ white               ┆ 583563      ┆ 0    ┆ 1999 │\n",
      "└─────────────────────────┴─────────────────────┴─────────────┴──────┴──────┘\n",
      "Number of unique user IDs: 10381144\n"
     ]
    }
   ],
   "source": [
    "# Path to the Parquet file\n",
    "parquet_file = \"./../2022_rplace.parquet\"\n",
    "\n",
    "# Read the first few rows of the Parquet file\n",
    "df = pl.read_parquet(parquet_file)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df)\n",
    "\n",
    "# Get the number of unique user IDs\n",
    "unique_user_ids = df[\"user_id_int\"].n_unique()\n",
    "\n",
    "# Print the number of unique user IDs\n",
    "print(f\"Number of unique user IDs: {unique_user_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
